{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from tensorflow.keras.models import Sequential # type: ignore\n",
        "from tensorflow.keras.layers import LSTM, Dense # type: ignore\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "#parameters\n",
        "look_back=96         #1 day of past data\n",
        "future_steps=720     #1 week of 15-min intervals\n",
        "epochs=3             #Reduced from 10\n",
        "batch_size=64        #Faster batch training\n",
        "\n",
        "#loading data\n",
        "prb_df=pd.read_csv(\"/content/drive/MyDrive/DL_Prb_Utilization_Data.csv\",parse_dates=[\"Timestamp\"],dayfirst=False)\n",
        "ue_df=pd.read_csv(\"/content/drive/MyDrive/Avg_UE_Number_Data.csv\",parse_dates=[\"Timestamp\"],dayfirst=False)\n",
        "\n",
        "#cleaning column names\n",
        "prb_df.columns=[col.strip() for col in prb_df.columns]\n",
        "ue_df.columns=[col.strip() for col in ue_df.columns]\n",
        "assert \"NCI\" in prb_df.columns and \"NCI\" in ue_df.columns\n",
        "\n",
        "def evaluate_forecast(y_true,y_pred):\n",
        "    r2=r2_score(y_true, y_pred)\n",
        "    return r2\n",
        "\n",
        "def create_dataset(series,look_back):\n",
        "    X,Y=[],[]\n",
        "    for i in range(len(series) - look_back):\n",
        "        X.append(series[i:i+look_back])\n",
        "        Y.append(series[i+look_back])\n",
        "    return np.array(X),np.array(Y)\n",
        "\n",
        "def forecast_lstm(df,kpi_col):\n",
        "    results=[]\n",
        "    all_forecasts=[]\n",
        "\n",
        "    target_cells=df[\"NCI\"].unique()\n",
        "\n",
        "    for cell in target_cells:\n",
        "      print(f\"\\n Processing cell {cell}\")\n",
        "      cell_df = df[df[\"NCI\"] == cell].sort_values(\"Timestamp\")\n",
        "\n",
        "      ts = cell_df[[\"Timestamp\", kpi_col]].dropna()\n",
        "      ts[\"Timestamp\"] = ts[\"Timestamp\"].astype(str).str.strip()\n",
        "\n",
        "      #Force correct format\n",
        "      ts[\"Timestamp\"] = pd.to_datetime(ts[\"Timestamp\"], format=\"%m-%d-%Y %H:%M\", errors=\"coerce\")\n",
        "      ts = ts.dropna(subset=[\"Timestamp\"])\n",
        "\n",
        "      #Filter from Feb 1,2024 to May 1,2025\n",
        "      ts = ts[(ts[\"Timestamp\"] >= \"2024-02-01 00:00:00\") & (ts[\"Timestamp\"] <= \"2025-05-01 23:45:00\")]\n",
        "      ts = ts.set_index(\"Timestamp\").sort_index()\n",
        "\n",
        "      try:\n",
        "        print(f\"Training data from {ts.index.min()} to {ts.index.max()}\")\n",
        "\n",
        "        values=ts.values.astype(\"float32\")\n",
        "        scaler=MinMaxScaler()\n",
        "        scaled=scaler.fit_transform(values)\n",
        "\n",
        "        X,y = create_dataset(scaled,look_back)\n",
        "        X = X.reshape((X.shape[0],X.shape[1],1))\n",
        "\n",
        "        split=int(len(X) * 0.8)\n",
        "        X_train,X_test = X[:split],X[split:]\n",
        "        y_train,y_test = y[:split],y[split:]\n",
        "\n",
        "        model=Sequential()\n",
        "        model.add(LSTM(50,input_shape=(look_back, 1)))\n",
        "        model.add(Dense(1))\n",
        "        model.compile(optimizer=\"adam\",loss=\"mean_squared_error\")\n",
        "        model.fit(X_train,y_train,epochs=3,batch_size=64,verbose=0)\n",
        "\n",
        "        y_pred=model.predict(X_test)\n",
        "        y_pred_inv=scaler.inverse_transform(y_pred)\n",
        "        y_test_inv=scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "\n",
        "        r2=evaluate_forecast(y_test_inv.flatten(),y_pred_inv.flatten())\n",
        "        results.append({\n",
        "            \"nCI\":cell,\n",
        "            \"Model\":\"LSTM\",\n",
        "            \"KPI\":kpi_col,\n",
        "            \"R2_Score\":r2,\n",
        "            \"LastTimestamp\":ts.index[-1]\n",
        "        })\n",
        "\n",
        "        #forecast\n",
        "        print(\"Forecasting from 2025-05-02 00:00:00 forward\")\n",
        "        forecast_scaled=[]\n",
        "        last_window=scaled[-look_back:].reshape(1,look_back,1)\n",
        "\n",
        "        for _ in range(future_steps):\n",
        "            pred= model.predict(last_window,verbose=0)\n",
        "            forecast_scaled.append(pred[0,0])\n",
        "            last_window=np.roll(last_window,-1,axis=1)\n",
        "            last_window[0,-1,0]=pred[0,0]\n",
        "\n",
        "        forecast = scaler.inverse_transform(np.array(forecast_scaled).reshape(-1,1))\n",
        "        future_start = pd.Timestamp(\"2025-05-02 00:00:00\")\n",
        "        future_dates = pd.date_range(\n",
        "            start=future_start,\n",
        "            periods=future_steps, freq=\"15min\"\n",
        "        )\n",
        "\n",
        "        forecast_df=pd.DataFrame({\n",
        "            \"Timestamp\":future_dates,\n",
        "            \"Forecast\":forecast.flatten(),\n",
        "            \"nCI\":cell,\n",
        "            \"KPI\":kpi_col\n",
        "        })\n",
        "        all_forecasts.append(forecast_df)\n",
        "\n",
        "      except Exception as e:\n",
        "        print(f\"Error processing cell {cell}:{e}\")\n",
        "        continue\n",
        "\n",
        "    if all_forecasts:\n",
        "        return pd.DataFrame(results),pd.concat(all_forecasts,ignore_index=True)\n",
        "    else:\n",
        "        print(\"No forecasts were generated.\")\n",
        "        return pd.DataFrame(results),pd.DataFrame()\n",
        "\n",
        "#forecast both KPIs\n",
        "prb_results,forecast_prb = forecast_lstm(prb_df,\"DL_Prb_Utilization\")\n",
        "ue_results,forecast_ue = forecast_lstm(ue_df,\"Avg_UE_Number\")\n",
        "\n",
        "#save to google drive\n",
        "forecast_prb.to_csv(\"/content/drive/MyDrive/forecast_DL_Prb_Utilization_LSTM.csv\",index=False)\n",
        "forecast_ue.to_csv(\"/content/drive/MyDrive/forecast_Avg_UE_Number_LSTM.csv\",index=False)\n",
        "pd.concat([prb_results, ue_results]).to_csv(\"/content/drive/MyDrive/model_accuracy_summary_LSTM.csv\",index=False)\n",
        "\n",
        "print(\"\\nForecasts saved to Google Drive.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EX29pSirQuY",
        "outputId": "92936f37-51d2-4b77-9756-02707431a16e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Processing cell 357783981\n",
            "Training data from 2024-02-01 00:00:00 to 2025-05-01 23:45:00\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step\n",
            "Forecasting from 2025-05-02 00:00:00 forward\n",
            "\n",
            " Processing cell 357783979\n",
            "Training data from 2024-02-01 00:00:00 to 2025-05-01 23:45:00\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step\n",
            "Forecasting from 2025-05-02 00:00:00 forward\n",
            "\n",
            " Processing cell 357783980\n",
            "Training data from 2024-02-01 00:00:00 to 2025-05-01 23:45:00\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step\n",
            "Forecasting from 2025-05-02 00:00:00 forward\n",
            "\n",
            " Processing cell 358531244\n",
            "Training data from 2024-02-01 00:00:00 to 2025-05-01 23:45:00\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step\n",
            "Forecasting from 2025-05-02 00:00:00 forward\n",
            "\n",
            " Processing cell 358531245\n",
            "Training data from 2024-02-01 00:00:00 to 2025-05-01 23:45:00\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step\n",
            "Forecasting from 2025-05-02 00:00:00 forward\n",
            "\n",
            " Processing cell 358531243\n",
            "Training data from 2024-02-01 00:00:00 to 2025-05-01 23:45:00\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step\n",
            "Forecasting from 2025-05-02 00:00:00 forward\n",
            "\n",
            " Processing cell 357783981\n",
            "Training data from 2024-02-01 00:00:00 to 2025-05-01 23:45:00\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step\n",
            "Forecasting from 2025-05-02 00:00:00 forward\n",
            "\n",
            " Processing cell 357783979\n",
            "Training data from 2024-02-01 00:00:00 to 2025-05-01 23:45:00\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step\n",
            "Forecasting from 2025-05-02 00:00:00 forward\n",
            "\n",
            " Processing cell 357783980\n",
            "Training data from 2024-02-01 00:00:00 to 2025-05-01 23:45:00\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step\n",
            "Forecasting from 2025-05-02 00:00:00 forward\n",
            "\n",
            " Processing cell 358531244\n",
            "Training data from 2024-02-01 00:00:00 to 2025-05-01 23:45:00\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step\n",
            "Forecasting from 2025-05-02 00:00:00 forward\n",
            "\n",
            " Processing cell 358531245\n",
            "Training data from 2024-02-01 00:00:00 to 2025-05-01 23:45:00\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step\n",
            "Forecasting from 2025-05-02 00:00:00 forward\n",
            "\n",
            " Processing cell 358531243\n",
            "Training data from 2024-02-01 00:00:00 to 2025-05-01 23:45:00\n",
            "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step\n",
            "Forecasting from 2025-05-02 00:00:00 forward\n",
            "\n",
            "Forecasts saved to Google Drive.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}